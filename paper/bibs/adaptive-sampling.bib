@article{Allocation2019,
author = {Allocation, Optimal and Stratified, I N and Schemes, Sampling},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/msc_optimal_allocation.pdf:pdf},
number = {199163},
title = {{Wojciech W{\'{o}}jciak}},
year = {2019}
}
@article{American2009,
author = {American, Source and Journal, Economic and Economics, Applied and October, No},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/American Economic Journal Applied Economics Volume 1 issue 4 2009 [doi 10.2307_25760187] Miriam Bruhn and David McKenzie -- In Pursuit of Balance- Randomization in Practice in Development Field Expe.pdf:pdf},
number = {4},
pages = {200--232},
title = {{American Economic Association In Pursuit of Balance : Randomization in Practice in Development Field Experiments Author ( s ): Miriam Bruhn and David McKenzie In Pursuit of Balance : Randomization in Practice in Development Field Experiments1}},
volume = {1},
year = {2009}
}
@article{Antos2010,
abstract = {We consider the problem of actively learning the mean values of distributions associated with a finite number of options. The decision maker can select which option to generate the next observation from, the goal being to produce estimates with equally good precision for all the options. If sample means are used to estimate the unknown values then the optimal solution, assuming that the distributions are known up to a shift, is to sample from each distribution proportional to its variance. No information other than the distributions' variances is needed to calculate the optimal solution. In this paper we propose an incremental algorithm that asymptotically achieves the same loss as an optimal rule. We prove that the excess loss suffered by this algorithm, apart from logarithmic factors, scales as n- 3 / 2, which we conjecture to be the optimal rate. The performance of the algorithm is illustrated on a simple problem. Crown Copyright {\textcopyright} 2010.},
author = {Antos, Andr{\'{a}}s and Grover, Varun and Szepesv{\'{a}}ri, Csaba},
doi = {10.1016/j.tcs.2010.04.007},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/1-s2.0-S0304397510002021-main.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Active learning,Heteroscedastic noise,Regression,Sequential allocation,Sequential analysis},
number = {29-30},
pages = {2712--2728},
publisher = {Elsevier B.V.},
title = {{Active learning in heteroscedastic noise}},
url = {http://dx.doi.org/10.1016/j.tcs.2010.04.007},
volume = {411},
year = {2010}
}
@unpublished{Aufenanger2017,
abstract = {This paper proposes a way of using observational pretest data for the design of experiments. In particular, this paper trains a random forest on the pretest data and stratifies the allocation of treatments to experimental units on the predicted dependent variables. This approach reduces much of the arbitrariness involved in defining strata directly on the basis of co-variates. A simulation on 300 random samples drawn from six data sets shows that this algorithm is extremely effective in reducing the variance of the estimation compared to random allocation and to traditional ways of stratification. On average, this stratification approach requires half the sample size to estimate the treatment effect with the same precision as complete randomization.},
author = {Aufenanger, Tobias},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/898624746.pdf:pdf},
issn = {1867-6707},
keywords = {C15,C90 Keywords: experiment design,JEL Classification: C14,treatment allocation},
title = {{Machine Learning to Improve Experimental Design}},
url = {https://www.iwf.rw.fau.de/research/iwf-discussion-paper-series/},
year = {2017}
}
@article{Bai2019,
author = {Bai, Yuehao},
doi = {10.2139/ssrn.3483834},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/SSRN-id3483834.pdf:pdf},
issn = {1556-5068},
journal = {SSRN Electronic Journal},
title = {{Optimality of Matched-Pair Designs in Randomized Controlled Trials}},
year = {2019}
}
@article{Barrios2014,
abstract = {This paper shows that stratifying on the conditional expectation of the outcome given baseline variables is optimal in matched-pair randomized experiments. The assign- ment minimizes the variance of the post-treatment difference in mean outcomes between treatment and controls. Optimal pairing depends only on predicted values of outcomes for experimental units, where the predicted values are the conditional expectations. After randomization, both frequentist inference and randomization inference depend only on the actual strata chosen and not on estimated predicted values. This gives experimenters away to use big data (possibly more covariates than the number of experimental units) ex-ante while maintaining simple post-experiment inference techniques. Optimizing the random- ization with respect to one outcome allows researchers to credibly signal the outcome of interest prior to the experiment. Inference can be conducted in the standard way by re- gressing the outcome on treatment and strata indicators. We illustrate the application of the methodology by running simulations based on a set of field experiments. We find that optimal designs have mean squared errors 23% less than randomized designs, on average. In one case, mean squared error is 43% less than randomized designs.},
author = {Barrios, Thomas},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/opstratv17_0.pdf:pdf},
pages = {1--70},
title = {{Optimal Stratification in Randomized Experiments}},
url = {http://scholar.harvard.edu/files/tbarrios/files/opstratv17_0.pdf},
year = {2014}
}
@article{Berry2004,
abstract = {The Bayesian approach is being used increasingly in medical research. The flexibility of the Bayesian approach allows for building designs of clinical trials that have good properties of any desired sort. Examples include maximizing effective treatment of patients in the trial, maximizing information about the slope of a dose-response curve, minimizing costs, minimizing the number of patients treated, minimizing the length of the trial and combinations of these desiderata. They also include standard frequentist operating characteristics when these are important considerations. Posterior probabilities are updated via Bayes' theorem on the basis of accumulating data. These are used to effect modifications of the trial's course, including stopping accrual, extending accrual beyond that originally planned, dropping treatment arms, adding arms, etc. An important aspect of the approach I advocate is modeling the relationship between a trial's primary endpoint and early indications of patient performance - auxiliary endpoints. This has several highly desirable consequences. One is that it improves the efficiency of adaptive trials because information is available sooner than otherwise.},
author = {Berry, Donald A.},
doi = {10.1214/088342304000000044},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/euclid.ss.1089808281.pdf:pdf},
issn = {08834237},
journal = {Statistical Science},
keywords = {Adaptive designs,Auxiliary end-points,Bayesian updating,Clinical ethics,Clinical trials,Decision analysis,Extraim analyses,Predictive probabilities},
number = {1},
pages = {175--187},
title = {{Bayesian statistics and the efficiency and ethics of clinical trials}},
volume = {19},
year = {2004}
}
@article{Breza,
author = {Breza, Emily},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/w23491.pdf:pdf},
title = {{USING AGGREGATED RELATIONAL DATA TO FEASIBLY IDENTIFY NETWORK STRUCTURE WITHOUT NETWORK DATA}}
}
@article{Brown2008,
abstract = {How to design an efficient large-area survey continues to be an interesting question for ecologists. In sampling large areas, as is common in environmental studies, adaptive sampling can be efficient because it ensures survey effort is targeted to subareas of high interest. In two-stage sampling, higher density primary sample units are usually of more interest than lower density primary units when populations are rare and clustered. Two-stage sequential sampling has been suggested as a method for allocating second stage sample effort among primary units. Here, we suggest a modification: adaptive two-stage sequential sampling. In this method, the adaptive part of the allocation process means the design is more flexible in how much extra effort can be directed to higher-abundance primary units. We discuss how best to design an adaptive two-stage sequential sample. {\textcopyright} 2008 The Society of Population Ecology and Springer.},
author = {Brown, Jennifer A. and {Salehi M.}, Mohammad and Moradi, Mohammad and Bell, Gavin and Smith, David R.},
doi = {10.1007/s10144-008-0089-1},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/Brown2008_Article_AnAdaptiveTwo-stageSequentialD.pdf:pdf},
isbn = {8415683111},
issn = {14383896},
journal = {Population Ecology},
keywords = {Murthy estimator,Optimal allocation,Rare clustered populations},
number = {3},
pages = {239--245},
title = {{An adaptive two-stage sequential design for sampling rare and clustered populations}},
volume = {50},
year = {2008}
}
@article{Caria2020,
abstract = {We introduce a novel methodology for adaptive targeted experiments. Our Tempered Thompson Algorithm balances the goals of maximizing the precision of treatment effect estimates and maximizing the welfare of experimental participants. A hierarchical Bayesian model allows us to adaptively target treatments at different groups. We implement our methodology in a field experiment. We examine the impact of three interventions designed to tackle credit constraints, information frictions and self-control challenges on formal employment outcomes of Syrian refugees and local jobseekers in Jordan. Six weeks after treatment, we find that treatments have had minimal effect on formal employment of refugees or locals. In the next draft of this paper, we will analyze longer-term employment and well-being outcomes and discuss further applications of adaptive targeted field experiments in economic development.},
author = {Caria, Stefano and Gordon, Grant and Kasy, Maximilian and Quinn, Simon and Shami, Soha and Teytelboym, Alexander},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/RefugeesWork.pdf:pdf},
journal = {Working Paper},
title = {{An Adaptive Targeted Field Experiment: Job Search Assistance for Refugees in Jordan}},
year = {2020}
}
@article{Carneiro2020,
abstract = {In a randomized control trial, the precision of an average treatment effect estimator and the power of the corresponding t-test can be improved either by collecting data on additional individuals, or by collecting additional covariates that predict the outcome variable. To design the experiment, a researcher needs to solve this trade-off subject to her budget constraint. We show that this optimization problem is equivalent to optimally predicting outcomes by the covariates, which in turn can be solved using existing machine learning techniques using pre-experimental data such as other similar studies, a census, or a household survey. In two empirical applications, we show that our procedure can lead to reductions of up to 58% in the costs of data collection, or improvements of the same magnitude in the precision of the treatment effect estimator.},
archivePrefix = {arXiv},
arxivId = {1603.03675},
author = {Carneiro, Pedro and Lee, Sokbae and Wilhelm, Daniel},
doi = {10.1093/ectj/utz020},
eprint = {1603.03675},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/utz020.pdf:pdf},
issn = {1368423X},
journal = {Econometrics Journal},
keywords = {data collection,machine learning,randomized control trials},
number = {1},
pages = {1--31},
title = {{Optimal data collection for randomized control trials}},
volume = {23},
year = {2020}
}
@article{Carpentier2011,
abstract = {We consider the problem of stratified sampling for Monte-Carlo integration. We model this problem in a multi-armed bandit setting, where the arms represent the strata, and the goal is to estimate a weighted average of the mean values of the arms. We propose a strategy that samples the arms according to an upper bound on their standard deviations and compare its estimation quality to an ideal allocation that would know the standard deviations of the strata. We provide two regret analyses: a distributiondependent bound {\~{O}}(n -3/2) that depends on a measure of the disparity of the strata, and a distribution-free bound {\~{O}} (n -4/3) that does not.},
author = {Carpentier, Alexandra and Munos, R{\'{e}}mi},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/4225-finite-time-analysis-of-stratified-sampling-for-monte-carlo.pdf:pdf},
isbn = {9781618395993},
journal = {Advances in Neural Information Processing Systems 24: 25th Annual Conference on Neural Information Processing Systems 2011, NIPS 2011},
pages = {1--9},
title = {{Finite-time analysis of stratified sampling for Monte Carlo}},
year = {2011}
}
@article{Carpentier2015,
abstract = {We consider the problem of stratified sampling for Monte Carlo integration of a random variable. We model this problem in a K-armed bandit, where the arms represent the K strata. The goal is to estimate the integral mean, that is a weighted average of the mean values of the arms. The learner is allowed to sample the variable n times, but it can decide on-line which stratum to sample next. We propose an UCB-type strategy that samples the arms according to an upper bound on their estimated standard deviations. We compare its performance to an ideal sample allocation that knows the standard deviations of the arms. For sub-Gaussian arm distributions, we provide bounds on the total regret: a distributiondependent bound of order poly($\lambda$min-1)O (n-3,2)1 that depends on a measure of the disparity $\lambda$min of the per stratum variances and a distribution-free bound poly(K)O (n-7/6) that does not. We give similar, but somewhat sharper bounds on a proxy of the regret. The problemindependent bound for this proxy matches its recent minimax lower bound in terms of n up to a log n factor.},
author = {Carpentier, Alexandra and Munos, Remi and Antos, Andr{\'{a}}s},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/carpentier15a.pdf:pdf},
issn = {15337928},
journal = {Journal of Machine Learning Research},
keywords = {Active learning,Adaptive sampling,Bandit theory,Minimax strategies,Stratified Monte Carlo},
pages = {2231--2271},
title = {{Adaptive strategy for stratified Monte Carlo sampling}},
volume = {16},
year = {2015}
}
@article{Chaloner1995,
author = {Chaloner, Kathryn and Verdinelli, Isabella},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/2246015.pdf:pdf},
keywords = {and phrases,decision theory,gistic regression,hierarchical linear models,lo-,nonlinear design,nonlinear models,optimal design,optimality criteria,utility functions},
title = {{Bayesian Experimental Design : A Review}},
year = {1995}
}
@article{Etore2011,
author = {Etore, Pierre and Fort, Gersende and Jourdain, Benjamin and Moulines, Eric},
doi = {10.1007/s10479-009-0638-9},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/aorpubli.pdf:pdf},
issn = {0254-5330},
journal = {Annals of Operations Research},
number = {1},
pages = {127--154},
title = {{On adaptive stratification}},
url = {http://link.springer.com/10.1007/s10479-009-0638-9},
volume = {189},
year = {2011}
}
@article{Goel2015,
abstract = {Probability-based sampling methods, such as random-digit dialing (RDD) of phones, are a staple of modern survey research and have been successfully used to gauge public opinion for sixty years. Though historically eﬀective, this class of traditional survey techniques are often slow and expensive. At the same time, it has become increasingly quick and costeﬀective to collect non-probability-based convenience samples, such as opt-in samples online. Here we investigate the potential of such nonrepresentative data for survey research by administering an online, fully opt-in poll of social and political attitudes. Our survey consisted of 49 multiple-choice attitudinal questions drawn from the probability-based, in-person 2012 General Social Survey (GSS) and select RDD phone surveys by the Pew Research Center. To correct for the inherent biases of non-representative data, we statistically adjust estimates via model-based poststratiﬁcation. Compared to typical RDD phone polls, the opt-in online survey required less than one-tenth the time and money to conduct. After statistical correction, we ﬁnd the median absolute diﬀerence between the non-probability-based online survey and the probability-based GSS and Pew studies is 7.4 percentage points. Though this diﬀerence is considerably larger than if the surveys were all perfect simple random samples, we ﬁnd the gap is comparable to that between the GSS and Pew estimates themselves, ostensibly because even the best available surveys suﬀer from substantial non-sampling error. We conclude that non-representative surveys are a promising tool for fast, cheap, and (mostly) accurate measurement of public opinion.},
author = {Goel, Sharad and Obeng, Adam and Rothschild, David},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/FastCheapAccurate.pdf:pdf},
pages = {27},
title = {{Non-Representative Surveys: Fast, Cheap, and Mostly Accurate}},
year = {2015}
}
@article{Handcock2012,
abstract = {Network models are widely used to represent relational information among interacting units and the structural implications of these relations. Recently, social network studies have focused a great deal of attention on random graph models of networks whose nodes represent individual social actors and whose edges represent a specified relationship between the actors. Most inference for social network models assumes that the presence or absence of all possible links is observed, that the information is completely reliable, and that there are no measurement (e.g., recording) errors. This is clearly not true in practice, as much network data is collected though sample surveys. In addition even if a census of a population is attempted, individuals and links between individuals are missed (i.e., do not appear in the recorded data). In this paper we develop the conceptual and computational theory for inference based on sampled network information. We first review forms of network sampling designs used in practice. We consider inference from the likelihood framework, and develop a typology of network data that reflects their treatment within this frame. We then develop inference for social network models based on information from adaptive network designs. We motivate and illustrate these ideas by analyzing the effect of link-tracing sampling designs on a collaboration network. {\textcopyright} 2010 Institute of Mathematical Statistics.},
author = {Handcock, Mark S. and Gile, Krista J.},
doi = {10.1214/08-AOAS221},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/euclid.aoas.1273584445.pdf:pdf},
issn = {19326157},
journal = {Annals of Applied Statistics},
keywords = {Design-based inference,Exponential family random graph model,Markov chain Monte Carlo,P model},
number = {1},
pages = {5--25},
title = {{Modeling social networks from sampled data}},
volume = {6},
year = {2012}
}
@article{Imai2009,
abstract = {A basic feature of many field experiments is that investigators are only able to randomize clusters of individuals-such as households, communities, firms, medical practices, schools or classrooms-even when the individual is the unit of interest. To recoup the resulting efficiency loss, some studies pair similar clusters and randomize treatment within pairs. However, many other studies avoid pairing, in part because of claims in the literature, echoed by clinical trials standards organizations, that this matched-pair, cluster-randomization design has serious problems. We argue that all such claims are unfounded. We also prove that the estimator recommended for this design in the literature is unbiased only in situations when matching is unnecessary; its standard error is also invalid. To overcome this problem without modeling assumptions, we develop a simple design-based estimator with much improved statistical properties. We also propose a model-based approach that includes some of the benefits of our design-based estimator as well as the estimator in the literature. Our methods also address individual-level noncompliance, which is common in applications but not allowed for in most existing methods. We show that from the perspective of bias, efficiency, power, robustness or research costs, and in large or small samples, pairing should be used in cluster-randomized experiments whenever feasible; failing to do so is equivalent to discarding a considerable fraction of one's data. We develop these techniques in the context of a randomized evaluation we are conducting of the Mexican Universal Health Insurance Program. {\textcopyright} Institute of Mathematical Statistics, 2009.},
author = {Imai, Kosuke and King, Gary and Nall, Clayton},
doi = {10.1214/08-STS274},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/euclid.ss.1255009008.pdf:pdf},
issn = {08834237},
journal = {Statistical Science},
keywords = {Causal inference,Community intervention trials,Field experiments,Group-randomized trials,Health policy,Matched-pair design,Noncompliance,Place-randomized trials,Power},
number = {1},
pages = {29--53},
title = {{The essential role of pair matching in cluster-randomized experiments, with application to the Mexican Universal Health Insurance Evaluation}},
volume = {24},
year = {2009}
}
@article{Jankowski2015,
abstract = {The uniqueness of online social networks makes it possible to implement new methods that increase the quality and effectiveness of research processes. While surveys are one of the most important tools for research, the representativeness of selected online samples is often a challenge and the results are hardly generalizable. An approach based on surveys with representativeness targeted at network measure distributions is proposed and analyzed in this paper. Its main goal is to focus not only on sample representativeness in terms of demographic attributes, but also to follow the measures distributions within main network. The approach presented has many application areas related to online research, sampling a network for the evaluation of collaborative learning processes, and candidate selection for training purposes with the ability to distribute information within a social network.},
author = {Jankowski, Jaros{\l}aw and Michalski, Rados{\l}aw and Br{\'{o}}dka, Piotr and Kazienko, Przemys{\l}aw and Utz, Sonja},
doi = {10.1016/j.chb.2014.12.015},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/1505.03049.pdf:pdf},
issn = {07475632},
journal = {Computers in Human Behavior},
keywords = {Adaptive surveys,Collaborative learning,Network sampling,Social network analysis},
pages = {685--693},
title = {{Knowledge acquisition from social platforms based on network distributions fitting}},
volume = {51},
year = {2015}
}
@article{Keeter2017,
abstract = {Telephone polls still provide accurate data on a wide range of social, demographic and political variables, but some weaknesses persist.},
author = {Keeter, Scott and Hatley, Nick and Kennedy, Courtney and Lau, Arnold},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/RDD-Non-response-Full-Report.pdf:pdf},
pages = {1--39},
title = {{What Low Response Rates Mean for Telephone Surveys}},
url = {http://www.pewresearch.org/wp-content/uploads/2017/05/RDD-Non-response-Full-Report.pdf},
year = {2017}
}
@book{Kivinen2011,
author = {Kivinen, Jyriki and Szepesv{\'{a}}ri, Csaba and Ukkonen, Esko and Zeugmann, Thomas},
doi = {10.1007/978-3-642-24412-4},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/2011_Book_AlgorithmicLearningTheory.pdf:pdf},
isbn = {9783642244124},
title = {{Algorithmic Learning Theory: 22nd International Conference, ALT 2011, Espoo, Finland, October 5-7, 2011, Proceedings}},
url = {http://books.google.com/books?hl=en&lr=&id=T8UVPK_5_3cC&oi=fnd&pg=PP2&dq=%22Conference+on+Discovery+Science+(DS+2011).+The+technical+program%22+%22on-line+learning+and+relative+loss+bounds,+semi-supervised+and%22+%22on+the+development+and+analysis+of+meth},
volume = {6925},
year = {2011}
}
@article{Moore2012,
abstract = {Political scientists use randomized treatment assignments to aid causal inference in field experiments, psychological laboratories, and survey research. Political research can do considerably better than completely randomized designs, but few political science experiments combine random treatment assignment with blocking on a rich set of background covariates. We describe high-dimensional multivariate blocking, including on continuous covariates, detail its statistical and political advantages over complete randomization, introduce a particular algorithm, and propose a procedure to mitigate unit interference in experiments. We demonstrate the performance of our algorithm in simulations and three field experiments from campaign politics and education. {\textcopyright} The Author 2012. Published by Oxford University Press on behalf of the Society for Political Methodology. All rights reserved.},
author = {Moore, Ryan T.},
doi = {10.1093/pan/mps025},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/Political Analysis Volume 20 issue 4 2012 [doi 10.1093_pan_mps025] Moore, R. T. -- Multivariate Continuous Blocking to Improve Political Science Experiments.pdf:pdf},
issn = {10471987},
journal = {Political Analysis},
number = {4},
pages = {460--479},
title = {{Multivariate continuous blocking to improve political science experiments}},
volume = {20},
year = {2012}
}
@article{Park2004,
abstract = {We fit a multilevel logistic regression model for the mean of a binary response variable conditional on poststratification cells. This approach combines the modeling approach often used in small-area estimation with the population information used in poststratification (see Gelman and Little 1997, Survey Methodology 23:127-135). To validate the method, we apply it to U.S. preelection polls for 1988 and 1992, poststratified by state, region, and the usual demographic variables. We evaluate the model by comparing it to state-level election outcomes. The multilevel model outperforms more commonly used models in political science. We envision the most important usage of this method to be not forecasting elections but estimating public opinion on a variety of issues at the state level. {\textcopyright} Society for Political Methodology 2004; all rights reserved.},
author = {Park, David K. and Gelman, Andrew and Bafumi, Joseph},
doi = {10.1093/pan/mph024},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/parkgelmanbafumi.pdf:pdf},
issn = {10471987},
journal = {Political Analysis},
number = {4},
pages = {375--385},
title = {{Bayesian multilevel estimation with poststratification: State-level estimates from national polls}},
volume = {12},
year = {2004}
}
@article{Peter,
author = {Peter, M and Berry, Don A and Grieve, Andrew P and Krams, Michael},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/MBGK06.pdf:pdf},
pages = {1--19},
title = {{A Bayesian Decision-Theoretic Dose Finding Trial}}
}
@article{Processes2019,
author = {Processes, Hydrological},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/BIOMTRKA-20-503-Proof-hi.pdf:pdf},
keywords = {approximations of operating characteristics,central limit theorem,directed trial designs,large sample,stochastic approximation},
title = {{Fo r P ee r R ev iew Fo r P modeling r R}},
year = {2019}
}
@article{Russo2018,
abstract = {We propose information-directed sampling-a new approach to online optimization problems in which a decision maker must balance between exploration and exploitation while learning from partial feedback. Each action is sampled in a manner that minimizes the ratio between squared expected single-period regret and a measure of information gain: the mutual information between the optimal action and the next observation. We establish an expected regret bound for information-directed sampling that applies across a very general class of models and scales with the entropy of the optimal action distribution. We illustrate through simple analytic examples how information-directed sampling accounts for kinds of information that alternative approaches do not adequately address and that this can lead to dramatic performance gains. For the widely studied Bernoulli, Gaussian, and linear bandit problems, we demonstrate state-of-the-art simulation performance.},
archivePrefix = {arXiv},
arxivId = {1403.5556},
author = {Russo, Daniel and {Van Roy}, Benjamin},
doi = {10.1287/opre.2017.1663},
eprint = {1403.5556},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/1403.5556.pdf:pdf},
issn = {15265463},
journal = {Operations Research},
keywords = {Exploration/exploitation,Information theory,Multi-armed bandit,Online optimization},
number = {1},
pages = {230--252},
title = {{Learning to optimize via information-directed sampling}},
volume = {66},
year = {2018}
}
@article{Salehi2010,
abstract = {In stratified sampling, methods for the allocation of effort among strata usually rely on some measure of within-stratum variance. If we do not have enough information about these variances, adaptive allocation can be used. In adaptive allocation designs, surveys are conducted in two phases. Information from the first phase is used to allocate the remaining units among the strata in the second phase. Brown et al. [Adaptive two-stage sequential sampling, Popul. Ecol. 50 (2008), pp. 239-245] introduced an adaptive allocation sampling design - where the final sample size was random - and an unbiased estimator. Here, we derive an unbiased variance estimator for the design, and consider a related design where the final sample size is fixed. Having a fixed final sample size can make survey-planning easier. We introduce a biased Horvitz-Thompson type estimator and a biased sample mean type estimator for the sampling designs.We conduct two simulation studies on honey producers in Kurdistan and synthetic zirconium distribution in a region on the moon. Results show that the introduced estimators are more efficient than the available estimators for both variable and fixed sample size designs, and the conventional unbiased estimator of stratified simple random sampling design. In order to evaluate efficiencies of the introduced designs and their estimator furthermore, we first review some well-known adaptive allocation designs and compare their estimator with the introduced estimators. Simulation results show that the introduced estimators are more efficient than available estimators of these well-known adaptive allocation designs. {\textcopyright} 2010 Taylor & Francis.},
author = {Salehi, Mohammad and Moradi, Mohammad and Brown, Jennifer A. and Smith, David},
doi = {10.1080/00949650903005664},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/Journal of Statistical Computation and Simulation Volume 80 issue 10 2010 [doi 10.1080_00949650903005664] Salehi, Mohammad\; Moradi, Mohammad\; Brown, Jennifer A.\; Smith, D -- Efficient estimators for.pdf:pdf},
isbn = {8415683111},
issn = {00949655},
journal = {Journal of Statistical Computation and Simulation},
keywords = {Adaptive allocation,Horvitz-thompson type estimator,Neyman's allocation,Sample mean type estimator},
number = {10},
pages = {1163--1179},
title = {{Efficient estimators for adaptive stratified sequential sampling}},
volume = {80},
year = {2010}
}
@article{Schneider2019,
abstract = {In this article, we explore the use of Facebook targeted advertisements for the collection of survey data. We illustrate the potential of survey sampling and recruitment on Facebook through the example of building a large employee–employer linked data set as part of The Shift Project. We describe the workflow process of targeting, creating, and purchasing survey recruitment advertisements on Facebook. We address concerns about sample selectivity and apply poststratification weighting techniques to adjust for differences between our sample and that of “gold standard” data sources. We then compare univariate and multivariate relationships in the Shift data against the Current Population Survey and the National Longitudinal Survey of Youth 1997. Finally, we provide an example of the utility of the firm-level nature of the data by showing how firm-level gender composition is related to wages. We conclude by discussing some important remaining limitations of the Facebook approach, as well as highlighting some unique strengths of the Facebook targeted advertisement approach, including the ability for rapid data collection in response to research opportunities, rich and flexible sample targeting capabilities, and low cost, and we suggest broader applications of this technique.},
author = {Schneider, Daniel and Harknett, Kristen},
doi = {10.1177/0049124119882477},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/0049124119882477.pdf:pdf},
issn = {15528294},
journal = {Sociological Methods and Research},
keywords = {firm-level data,gender,nonprobability sampling,survey methods,work},
title = {{What's to Like? Facebook as a Tool for Survey Data Collection}},
year = {2019}
}
@book{Seber,
author = {Seber, George A.F. and Salehi, Mohammad M.},
doi = {10.1007/978-3-642-33657-7},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/[SpringerBriefs in Statistics] George A.F. Seber, Mohammad M. Salehi (auth.) - Adaptive Sampling Designs_ Inference for Sparse and Clustered Populations (2013, Springer-Verlag Berlin Heidelberg) - libgen.lc.pdf:pdf},
isbn = {978-3-642-33656-0},
publisher = {Springer Berlin Heidelberg},
series = {SpringerBriefs in Statistics},
title = {{Adaptive Sampling Designs}},
url = {http://www.springer.com/series/8921 http://link.springer.com/10.1007/978-3-642-33657-7}
}
@article{Shekhar2019,
abstract = {We consider the problem of allocating samples to a finite set of discrete distributions in order to learn them uniformly well in terms of four common distance measures: $\ell_2^2$, $\ell_1$, $f$-divergence, and separation distance. To present a unified treatment of these distances, we first propose a general optimistic tracking algorithm and analyze its sample allocation performance w.r.t.$\sim$an oracle. We then instantiate this algorithm for the four distance measures and derive bounds on the regret of their resulting allocation schemes. We verify our theoretical findings through some experiments. Finally, we show that the techniques developed in the paper can be easily extended to the related setting of minimizing the average error (in terms of the four distances) in learning a set of distributions.},
archivePrefix = {arXiv},
arxivId = {1910.12406},
author = {Shekhar, Shubhanshu and Javidi, Tara and Ghavamzadeh, Mohammad},
eprint = {1910.12406},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/ICML-2020-adaptive-sampling-for-estimating-probability-distributions-Paper.pdf:pdf},
number = {2013},
title = {{Adaptive Sampling for Estimating Multiple Probability Distributions}},
url = {http://arxiv.org/abs/1910.12406},
year = {2019}
}
@article{Tabord-Meehan2020,
abstract = {This paper proposes an adaptive randomization procedure for two-stage randomized controlled trials. The method uses data from a first-wave experiment in order to determine how to stratify in a second wave of the experiment, where the objective is to minimize the variance of an estimator for the average treatment effect (ATE). We consider selection from a class of stratified randomization procedures which we call stratification trees: these are procedures whose strata can be represented as decision trees, with differing treatment assignment probabilities across strata. By using the first wave to estimate a stratification tree, we simultaneously select which covariates to use for stratification, how to stratify over these covariates, as well as the assignment probabilities within these strata. Our main result shows that using this randomization procedure with an appropriate estimator results in an asymptotic variance which is minimal in the class of stratification trees. Moreover, the results we present are able to accommodate a large class of assignment mechanisms within strata, including stratified block randomization. In a simulation study, we find that our method, paired with an appropriate cross-validation procedure ,can improve on ad-hoc choices of stratification. We conclude by applying our method to the study in Karlan and Wood (2017), where we estimate stratification trees using the first wave of their experiment.},
archivePrefix = {arXiv},
arxivId = {1806.05127},
author = {Tabord-Meehan, Max},
eprint = {1806.05127},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/1806.05127.pdf:pdf},
keywords = {adaptive randomization,c14,c21,c93,decision trees,jel classification codes,randomized experiments},
title = {{Stratification Trees for Adaptive Randomization in Randomized Controlled Trials}},
url = {http://arxiv.org/abs/1806.05127},
year = {2020}
}
@article{Thompson2011,
abstract = {This paper describes recent developments in adaptive sampling strategies and introduces new variations on those strategies. Recent developments described included targeted random walk designs and adaptive web sampling. These designs are particularly suited for sampling in networks; for example, for finding a sample of people from a hidden human population by following social links from sample individuals to find additional members of the hidden population to add to the sample. Each of these designs can also be translated into spatial settings to produce flexible new spatial adaptive strategies for sampling unevenly distributed populations. Variations on these sampling strategies include versions in which the network or spatial links have unequal weights and are followed with unequal probabilities.},
author = {Thompson, Steve},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/11607-eng.pdf:pdf},
issn = {07140045},
journal = {Survey Methodology},
keywords = {Adaptive web sampling,Markov chain,Network sampling,Random walk,Snowball sampling},
number = {2},
pages = {183--196},
title = {{Adaptive network and spatial sampling}},
volume = {37},
year = {2011}
}
@article{Viviano2019,
abstract = {This paper discusses the problem of estimating individualized treatment allocation rules under network interference. We propose a method with several appealing features for applications: we let treatment and spillover effects be heterogeneous in the population, and we construct targeting rules that exploit such heterogeneity; we accommodate for arbitrary, possibly non-linear, regression models, and we propose estimators that are robust to model misspecification; treatment allocation rules depend on an arbitrary set of individual, neighbors' and network characteristics, and we allow for general constraints on the policy function and capacity constraints on the number of treated units; the proposed methodology is valid also when only local information of the network is observed. From a theoretical perspective, we establish the first set of guarantees on the utilitarian regret under interference, and we show that it achieves the min-max optimal rate in scenarios of practical and theoretical interest. We provide a mixed-integer linear program formulation of the optimization problem, that can be solved using standard optimization routines. We discuss the empirical performance in simulations, and we illustrate our method by investigating the role of social networks in micro-finance decisions.},
archivePrefix = {arXiv},
arxivId = {1906.10258},
author = {Viviano, Davide},
eprint = {1906.10258},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/2003.08421.pdf:pdf},
pages = {1--55},
title = {{Policy Targeting under Network Interference}},
url = {http://arxiv.org/abs/1906.10258},
year = {2019}
}
@article{Wang2015,
abstract = {Election forecasts have traditionally been based on representative polls, in which randomly sampled individuals are asked who they intend to vote for. While representative polling has historically proven to be quite effective, it comes at considerable costs of time and money. Moreover, as response rates have declined over the past several decades, the statistical benefits of representative sampling have diminished. In this paper, we show that, with proper statistical adjustment, non-representative polls can be used to generate accurate election forecasts, and that this can often be achieved faster and at a lesser expense than traditional survey methods. We demonstrate this approach by creating forecasts from a novel and highly non-representative survey dataset: a series of daily voter intention polls for the 2012 presidential election conducted on the Xbox gaming platform. After adjusting the Xbox responses via multilevel regression and poststratification, we obtain estimates which are in line with the forecasts from leading poll analysts, which were based on aggregating hundreds of traditional polls conducted during the election cycle. We conclude by arguing that non-representative polling shows promise not only for election forecasting, but also for measuring public opinion on a broad range of social, economic and cultural issues.},
author = {Wang, Wei and Rothschild, David and Goel, Sharad and Gelman, Andrew},
doi = {10.1016/j.ijforecast.2014.06.001},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/International Journal of Forecasting Volume 31 issue 3 2015 [doi 10.1016_j.ijforecast.2014.06.001] Wang, Wei\; Rothschild, David\; Goel, Sharad\; Gelman, Andrew -- Forecasting elections with non-repres.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {Election forecasting,Multilevel regression and poststratification,Non-representative polling},
number = {3},
pages = {980--991},
publisher = {Elsevier B.V.},
title = {{Forecasting elections with non-representative polls}},
url = {http://dx.doi.org/10.1016/j.ijforecast.2014.06.001},
volume = {31},
year = {2015}
}
@article{Zacks1969,
abstract = {The problem of choosing a sample of a fixed size from a finite population is studied in the framework of Bayes designs. The conjectured non-randomized character of Bayes designs is verified. Bayes designs are shown to be without replacement selections, which are generally sequential ones. Sufficient conditions are provided for the optimality of single-phase designs. An example is provided of a case in which the optimal Bayes design is sequential. {\textcopyright} Taylor & Francis Group, LLC.},
author = {Zacks, Shelley},
doi = {10.1080/01621459.1969.10501060},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/Journal of the American Statistical Association Volume 64 issue 328 1969 [doi 10.1080_01621459.1969.10501060] Zacks, Shelley -- Bayes Sequential Designs of Fixed Size Samples from Finite Populations.pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
number = {328},
pages = {1342--1349},
title = {{Bayes Sequential Designs of Fixed Size Samples from Finite Populations}},
volume = {64},
year = {1969}
}
@article{Zagheni2017,
author = {Zagheni, Emilio and Weber, Ingmar and Gummadi, Krishna},
doi = {10.1111/padr.12102},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/padr.12102.pdf:pdf},
issn = {17284457},
journal = {Population and Development Review},
number = {4},
pages = {721--734},
title = {{Leveraging Facebook's Advertising Platform to Monitor Stocks of Migrants}},
volume = {43},
year = {2017}
}
